Page: modal.com_files/modal.com/docs/guide/concurrent-inputs.html
----------------------------------------
   [1]Modal logo
   [2]Guide [3]Examples [4]Reference [5]Playground
   [6]Log In [7]Sign Up
   (BUTTON)
   [8]Introduction[9]Custom container images [10]Custom
   containers[11]Private registries[12]GPUs and other resources [13]GPU
   acceleration[14]Using CUDA on Modal[15]Reserving CPU and
   memory[16]Scaling out [17]Scaling out[18]Dicts and queues[19]Job
   processing[20]Concurrent inputs on a single container (beta)[21]Dynamic
   batching (beta)[22]Scheduling and cron jobs[23]Deployment [24]Apps,
   Stubs, and entrypoints[25]Managing deployments[26]Invoke deployed
   functions[27]Continuous deployment[28]Secrets and environment variables
   [29]Secrets[30]Environment variables[31]Web endpoints [32]Web
   endpoints[33]Streaming endpoints[34]Web endpoint URLs[35]Request
   timeouts[36]Networking [37]Tunnels (beta)[38]Proxies (beta)[39]Data
   sharing and storage [40]Passing local data[41]Volumes[42]Mounting local
   files and directories[43]Storing model weights[44]Dataset
   ingestion[45]Cloud bucket mounts[46]Network file systems
   (superseded)[47]Sandboxes [48]Sandboxes[49]Running
   commands[50]Networking and security[51]File access[52]Performance
   [53]Cold start performance[54]Memory Snapshot (beta)[55]Geographic
   latency[56]Reliability and robustness [57]Failures and
   retries[58]Preemption[59]Timeouts[60]Troubleshooting[61]Security and
   privacy[62]Integrations [63]Connecting Modal to your Vercel
   account[64]Connecting Modal to your Datadog account[65]Connecting Modal
   to your OpenTelemetry provider[66]Okta SSO[67]Slack notifications
   (beta)[68]Other topics [69]File and project structure[70]Developing and
   debugging[71]Modal user account
   setup[72]Workspaces[73]Environments[74]Jupyter
   notebooks[75]Asynchronous API usage[76]Global variables[77]Region
   selection[78]Container lifecycle hooks[79]Parameterized functions[80]S3
   Gateway endpoints
     __________________________________________________________________

Concurrent inputs on a single container (beta)

   This guide explores why and how to configure containers to process
   multiple inputs simultaneously.

Default parallelism

   Modal offers beautifully simple parallelism: when there is a large
   backlog of inputs enqueued, the number of containers scales up
   automatically. This is the ideal source of parallelism in the majority
   of cases.

When to use concurrent inputs

   There are, however, a few cases where it is ideal to run multiple
   inputs on each container concurrently.

   One use case is hosting [81]web applications where the endpoints are
   not CPU-bound - for example, making an asynchronous request to a
   deployed Modal function or querying a database. Only a handful of
   containers can handle hundreds of simultaneous requests for such
   applications if you allow concurrent inputs.

   Another use case is to support continuous batching on GPU-accelerated
   containers. Frameworks such as [82]vLLM allow us to push higher token
   throughputs by maximizing compute in each forward pass. In LLMs, this
   means each GPU step can generate tokens for multiple user queries; in
   diffusion models, you can denoise multiple images concurrently. In
   order to take full advantage of this, containers need to be processing
   multiple inputs concurrently.

Configuring concurrent inputs within a container

   To configure functions to allow each individual container to process n
   inputs concurrently, set allow_concurrent_inputs=n on the function
   decorator.

   The Modal container will execute concurrent inputs on separate threads
   if the function is synchronous. You must ensure that the function
   implementation is thread-safe.

   On the other hand, if the function is asynchronous, the Modal container
   will execute the concurrent inputs on separate asyncio tasks, using a
   single thread. Allowing concurrent inputs inside an async function does
   not require the function to be thread-safe.
# Each container executes up to 10 inputs in separate threads
@app.function(allow_concurrent_inputs=10)
def sleep_sync():
    # Function must be thread-safe
    time.sleep(1)

# Each container executes up to 10 inputs in separate async tasks
@app.function(allow_concurrent_inputs=10)
async def sleep_async():
    await asyncio.sleep(1)

   (BUTTON) Copy

   This is an advanced feature, and you should make sure that your
   function satisfies the requirements outlined before proceeding with
   concurrent inputs.

How does autoscaling work on Modal?

   To recap, there are three different scaling parameters you can set on
   each function:
     * concurrency_limit controls the maximum number of containers
       (default: None).
     * keep_warm controls the number of "warm" containers that should be
       kept running, even during periods of reduced traffic (default: 0).
     * allow_concurrent_inputs sets the capacity of a single container to
       handle some number of simultaneous inputs (default: 1).

   Modal uses these three parameters, as well as traffic and your
   container_idle_timeout, to determine when to create new runners or
   decommission old ones. This is done on a per-function basis. Each Modal
   function gets its own, independently scaling pool of runners.

   A new container is created when the number of inputs exceeds the total
   capacity of all running containers. This means that there are inputs
   waiting to be processed. Containers are removed when they are no longer
   serving traffic. For example:
       allow_concurrent_inputs=20, and there are 100 inputs enqueued.
       container will process 20 inputs concurrently. There are now 100
       inputs running.
       100 running inputs. Modal will create a new container.
       become idle.

   Our automatic scaling is fine-grained, and containers are spawned
   immediately after an input is received that exceeds the current
   runners' capacity.
   [83]Concurrent inputs on a single container (beta) [84]Default
   parallelism [85]When to use concurrent inputs [86]Configuring
   concurrent inputs within a container [87]How does autoscaling work on
   Modal?
   See it in action
   [88]Single GPU serving concurrent requests
   [89]Responsive web app on one low-cost container
   Modal logo Â© 2024
   [90]About [91]Status [92]Changelog [93]Documentation [94]Slack
   Community [95]Pricing [96]Examples

