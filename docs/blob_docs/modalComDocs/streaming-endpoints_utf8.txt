Page: modal.com_files/modal.com/docs/guide/streaming-endpoints.html
----------------------------------------
   [1]Modal logo
   [2]Guide [3]Examples [4]Reference [5]Playground
   [6]Log In [7]Sign Up
   (BUTTON)
   [8]Introduction[9]Custom container images [10]Custom
   containers[11]Private registries[12]GPUs and other resources [13]GPU
   acceleration[14]Using CUDA on Modal[15]Reserving CPU and
   memory[16]Scaling out [17]Scaling out[18]Dicts and queues[19]Job
   processing[20]Concurrent inputs on a single container (beta)[21]Dynamic
   batching (beta)[22]Scheduling and cron jobs[23]Deployment [24]Apps,
   Stubs, and entrypoints[25]Managing deployments[26]Invoke deployed
   functions[27]Continuous deployment[28]Secrets and environment variables
   [29]Secrets[30]Environment variables[31]Web endpoints [32]Web
   endpoints[33]Streaming endpoints[34]Web endpoint URLs[35]Request
   timeouts[36]Networking [37]Tunnels (beta)[38]Proxies (beta)[39]Data
   sharing and storage [40]Passing local data[41]Volumes[42]Mounting local
   files and directories[43]Storing model weights[44]Dataset
   ingestion[45]Cloud bucket mounts[46]Network file systems
   (superseded)[47]Sandboxes [48]Sandboxes[49]Running
   commands[50]Networking and security[51]File access[52]Performance
   [53]Cold start performance[54]Memory Snapshot (beta)[55]Geographic
   latency[56]Reliability and robustness [57]Failures and
   retries[58]Preemption[59]Timeouts[60]Troubleshooting[61]Security and
   privacy[62]Integrations [63]Connecting Modal to your Vercel
   account[64]Connecting Modal to your Datadog account[65]Connecting Modal
   to your OpenTelemetry provider[66]Okta SSO[67]Slack notifications
   (beta)[68]Other topics [69]File and project structure[70]Developing and
   debugging[71]Modal user account
   setup[72]Workspaces[73]Environments[74]Jupyter
   notebooks[75]Asynchronous API usage[76]Global variables[77]Region
   selection[78]Container lifecycle hooks[79]Parameterized functions[80]S3
   Gateway endpoints
     __________________________________________________________________

Streaming endpoints

   Modal web endpoints support streaming responses using FastAPI's
   [81]StreamingResponse class. This class accepts asynchronous
   generators, synchronous generators, or any Python object that
   implements the [82]iterator protocol, and can be used with Modal
   Functions!

Simple example

   This simple example combines Modal's @web_endpoint decorator with a
   StreamingResponse object to produce a real-time SSE response.
import time

import modal

image = modal.Image.debian_slim().pip_install("fastapi[standard]")
app = modal.App(image=image)


def fake_event_streamer():
    for i in range(10):
        yield f"data: some data {i}\n\n".encode()
        time.sleep(0.5)


@app.function()
@modal.web_endpoint()
def stream_me():
    from fastapi.responses import StreamingResponse
    return StreamingResponse(
        fake_event_streamer(), media_type="text/event-stream"
    )

   (BUTTON) Copy

   If you serve this web endpoint and hit it with curl, you will see the
   ten SSE events progressively appear in your terminal over a ~5 second
   period.
curl --no-buffer https://modal-labs--example-streaming-stream-me.modal.run

   (BUTTON) Copy

   The MIME type of text/event-stream is important in this example, as it
   tells the downstream web server to return responses immediately, rather
   than buffering them in byte chunks (which is more efficient for
   compression).

   You can still return other content types like large files in streams,
   but they are not guaranteed to arrive as real-time events.

Streaming responses with .remote

   A Modal Function wrapping a generator function body can have its
   response passed directly into a StreamingResponse. This is particularly
   useful if you want to do some GPU processing in one Modal Function that
   is called by a CPU-based web endpoint Modal Function.
from fastapi.responses import StreamingResponse

import modal

app = modal.App()


@app.function(gpu="any")
def fake_video_render():
    for i in range(10):
        yield f"data: finished processing some data from GPU {i}\n\n".encode()
        time.sleep(1)


@app.function()
@modal.web_endpoint()
def hook():
    return StreamingResponse(
        fake_video_render.remote(), media_type="text/event-stream"
    )

   (BUTTON) Copy

Streaming responses with .map and .starmap

   You can also combine Modal Function parallelization with streaming
   responses, enabling applications to service a request by farming out to
   dozens of containers and iteratively returning result chunks to the
   client.
from fastapi.responses import StreamingResponse

import modal

app = modal.App()


@app.function()
def map_me(i):
    return f"segment {i}\n"


@app.function()
@modal.web_endpoint()
def mapped():
    return StreamingResponse(map_me.map(range(10)), media_type="text/plain")

   (BUTTON) Copy

   This snippet will spread the ten map_me(i) executions across
   containers, and return each string response part as it completes. By
   default the results will be ordered, but if this isn't necessary pass
   order_outputs=False as keyword argument to the .map call.

Asynchronous streaming

   The example above uses a synchronous generator, which automatically
   runs on its own thread, but in asynchronous applications, a loop over a
   .map or .starmap call can block the event loop. This will stop the
   StreamingResponse from returning response parts iteratively to the
   client.

   To avoid this, you can use the .aio() method to convert a synchronous
   .map into its async version. Also, other blocking calls should be
   offloaded to a separate thread with asyncio.to_thread(). For example:
import modal


@app.function(gpu="any")
@modal.web_endpoint()
async def transcribe_video(request):
    segments = await asyncio.to_thread(split_video, request)
    return StreamingResponse(wrapper(segments), media_type="text/event-stream")


# Notice that this is an async generator.
async def wrapper(segments):
    async for partial_result in transcribe_video.map.aio(segments):
        yield "data: " + partial_result + "\n\n"

   (BUTTON) Copy

Further examples

     * Complete code the for the simple examples given above is available
       [83]in our modal-examples Github repository.
     * [84]An end-to-end example of streaming Youtube video transcriptions
       with OpenAI's whisper model.

   [85]Streaming endpoints [86]Simple example [87]Streaming responses with
   .remote [88]Streaming responses with .map and .starmap [89]Asynchronous
   streaming [90]Further examples
   See it in action
   [91]LLM Voice Chat
   [92]Text Generation Inference
   Modal logo Â© 2024
   [93]About [94]Status [95]Changelog [96]Documentation [97]Slack
   Community [98]Pricing [99]Examples

